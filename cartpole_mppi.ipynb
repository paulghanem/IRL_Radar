{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T23:08:23.825375Z",
     "start_time": "2025-01-07T23:08:22.802397Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T23:08:28.165353Z",
     "start_time": "2025-01-07T23:08:23.828375Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "# Set the number of (emulated) host devices\n",
    "num_devices = 4\n",
    "os.environ['XLA_FLAGS'] = f\"--xla_force_host_platform_device_count={num_devices}\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import gymnax\n",
    "from gymnax.visualize import Visualizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "jax.device_count(), jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T23:08:37.783669Z",
     "start_time": "2025-01-07T23:08:28.157339Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from utils.models import get_model_ready\n",
    "from utils.helpers import load_config, save_pkl_object\n",
    "\n",
    "\n",
    "from src.control.dynamics import get_state,get_step_model,kinematics,get_action_space,get_cov_coef\n",
    "from src.control.MPPI import MPPI_wrapper,weighting,MPPI_scores_wrapper,MPPI_control,weighting\n",
    "from src.objective_fns.cost_to_go_fns import get_cost\n",
    "from src.objective_fns.objectives import MPC_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gym_env = \"MountainCarContinuous-v0\"\n",
    "# gym_env = \"CartPole-v1\"\n",
    "gym_env = \"Pendulum-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_rollout = jax.jit(partial(kinematics,step_fn=get_step_model(gym_env)))\n",
    "\n",
    "mppi = MPPI_wrapper(dynamic_rollout)\n",
    "\n",
    "mpc_obj = MPC_decorator(get_cost(gym_env),dynamic_rollout,0.99) #0.99)\n",
    "\n",
    "mppi_scores = MPPI_scores_wrapper(mpc_obj)\n",
    "\n",
    "weight_fn = weighting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "\n",
    "args.num_traj = 250\n",
    "args.horizon = 75\n",
    "args.MPPI_iterations=150\n",
    "\n",
    "episode_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_key = jax.random.PRNGKey(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gym_env == \"CartPole-v1\":\n",
    "  state = jnp.array([1.7,0.04,0.02,-0.05])\n",
    "if gym_env == \"Pendulum-v1\":\n",
    "  state = jnp.array([-0.69552635 , 0.71850059, -0.113958])\n",
    "if gym_env == \"MountainCarContinuous-v0\":\n",
    "  state = jnp.array([-0.50243301,  0.        ])\n",
    "  \n",
    "U = jnp.array(np.random.randn(15,args.horizon,1)*0)\n",
    "U_nominal = U.mean(axis=0)\n",
    "\n",
    "cov = jnp.eye(args.horizon)*get_cov_coef(gym_env)\n",
    "\n",
    "# covariance is very important!!!!\n",
    "# 10 for CartPole-v1\n",
    "# 1.5 for Pendulum\n",
    "# 1.0 for Mountaincar\n",
    "# gamma is 1 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t: 151 State: [ 0.99948025 -0.0322371  -0.66186963] Action: [2.] Cost: 0.044846641762232936: 100%|████████████████████████████| 150/150 [01:36<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "state_seq_mppi = [get_state(state,action=U_nominal[-1],time=0,env_name=gym_env)]\n",
    "                  \n",
    "                \n",
    "rewards = [get_cost(env_name=gym_env)(state)]\n",
    "\n",
    "pbar = tqdm(total=episode_length, desc=\"Starting\")\n",
    "\n",
    "for i in range(1,episode_length+1):\n",
    "  (U_nominal,cov_prime), (states,states_MPPI), cost_MPPI, key = MPPI_control(state,U_nominal,cov,random_key,\n",
    "              dynamic_rollout,get_action_space(gym_env),\n",
    "              mppi,mppi_scores,weight_fn,\n",
    "              method=None,state_train=None,\n",
    "              args=args)\n",
    "  \n",
    "  state = states[0]\n",
    "  rewards.append(get_cost(env_name=gym_env)(state))\n",
    "  state_seq_mppi.append(get_state(state,action=U_nominal[-1],time=i,env_name=gym_env))\n",
    "\n",
    "# print(U_nominal.shape)\n",
    "# print(\"U: \",U_nominal)\n",
    "  pbar.set_description(f\"t: {i+1} State: {state} Action: {U_nominal[0]} Cost: {get_cost(env_name=gym_env)(state)}\")\n",
    "  pbar.update(1)\n",
    "  \n",
    "pbar.close()\n",
    "\n",
    "rewards = np.array(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base =  osp.join(\"expert_agents\",gym_env,\"ppo\")\n",
    "configs = load_config(base + \".yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvParams(max_steps_in_episode=999, min_action=-1.0, max_action=1.0, min_position=-1.2, max_position=0.6, max_speed=0.07, goal_position=0.45, goal_velocity=0.0, power=0.0015, gravity=0.0025)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env, env_params = gymnax.make(\n",
    "        configs.train_config.env_name,\n",
    "        **configs.train_config.env_kwargs,\n",
    "    )\n",
    "env_params.replace(**configs.train_config.env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer(env, env_params, state_seq_mppi, rewards)\n",
    "vis.animate(osp.join(\"results\",f\"{gym_env}-mppi.gif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Action Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gym_env == \"CartPole-v1\":\n",
    "  state = jnp.array([1.5,0.04,0.02,-0.05])\n",
    "if gym_env == \"Pendulum-v1\":\n",
    "  state = jnp.array([-0.69552635 , 0.71850059, -0.113958])\n",
    "  \n",
    "U = jnp.array(np.random.randn(15,args.horizon,1)*0.2)\n",
    "U_nominal = U.mean(axis=0)\n",
    "\n",
    "cov = jnp.eye(args.horizon)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_seq_random = [get_state(state,action=U_nominal[-1],time=0,env_name=gym_env)]\n",
    "rewards = [get_cost(env_name=gym_env)(state)]\n",
    "pbar = tqdm(total=episode_length, desc=\"Starting\")\n",
    "\n",
    "for i in range(1,episode_length+1):\n",
    "  action = jnp.array(np.random.randn(1,))*5\n",
    "  action = jnp.clip(action,-10,10)\n",
    "\n",
    "  \n",
    "  state = get_step_model(gym_env)(action,state)\n",
    "  \n",
    "  rewards.append(get_cost(env_name=gym_env)(state))\n",
    "  state_seq_random.append(get_state(state,action=action,time=i,env_name=gym_env))\n",
    "\n",
    "# print(U_nominal.shape)\n",
    "# print(\"U: \",U_nominal)\n",
    "  # print(\"State: \",state, \"Action: \",action)\n",
    "  pbar.set_description(f\"t: {i+1} State: {state} Action: {U_nominal[0]}\")\n",
    "  pbar.update(1)\n",
    "  \n",
    "pbar.close()\n",
    "\n",
    "rewards = np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer(env, env_params, state_seq_random,rewards)\n",
    "vis.animate(osp.join(\"results\",f\"{gym_env}-random.gif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expert Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models import load_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_env = \"Pendulum-v1\"\n",
    "base =  osp.join(\"expert_agents\",gym_env,\"ppo\")\n",
    "configs = load_config(base + \".yaml\")\n",
    "model, model_params = load_neural_network(\n",
    "    configs.train_config, base + \".pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_episode(env, env_params, model, model_params, max_frames=200):\n",
    "    state_seq = []\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "\n",
    "    rng, rng_reset = jax.random.split(rng)\n",
    "    obs, env_state = env.reset(rng_reset, env_params)\n",
    "\n",
    "    if gym_env == \"CartPole-v1\":\n",
    "      obs = jnp.array([1.5,0.04,0.02,-0.05])\n",
    "      env_state = get_state(obs,time=0,env_name=gym_env)\n",
    "\n",
    "\n",
    "  \n",
    "    if model is not None:\n",
    "        if model.model_name == \"LSTM\":\n",
    "            hidden = model.initialize_carry()\n",
    "\n",
    "    t_counter = 0\n",
    "    reward_seq = []\n",
    "    action = 0\n",
    "    while True:\n",
    "        state_seq.append(get_state(obs,action,time=t_counter,env_name=gym_env))\n",
    "        rng, rng_act, rng_step = jax.random.split(rng, 3)\n",
    "\n",
    "        if model.model_name.startswith(\"separate\"):\n",
    "            v, pi = model.apply(model_params, obs, rng_act)\n",
    "            action = pi.sample(seed=rng_act)\n",
    "\n",
    "        else:\n",
    "            action = model.apply(model_params, obs, rng_act)\n",
    "\n",
    "        next_obs, next_env_state, reward, done, info = env.step(\n",
    "            rng_step, env_state,action, env_params\n",
    "        )\n",
    "      \n",
    "        reward_seq.append(reward)\n",
    "        print(t_counter, reward, obs, env_state.theta,action, done)\n",
    "        print(10 * \"=\")\n",
    "        t_counter += 1\n",
    "        if done or t_counter == max_frames:\n",
    "            break\n",
    "        else:\n",
    "            env_state = next_env_state\n",
    "            obs = next_obs\n",
    "    print(f\"{env.name} - Steps: {t_counter}, Return: {np.sum(reward_seq)}\")\n",
    "    return state_seq, np.cumsum(reward_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env, env_params = gymnax.make(\n",
    "        configs.train_config.env_name,\n",
    "        **configs.train_config.env_kwargs,\n",
    "    )\n",
    "env_params.replace(**configs.train_config.env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env, env_params = gymnax.make(\n",
    "        configs.train_config.env_name,\n",
    "        **configs.train_config.env_kwargs,\n",
    "    )\n",
    "env_params.replace(**configs.train_config.env_params)\n",
    "state_seq, cum_rewards = rollout_episode(\n",
    "    env, env_params, model, model_params,max_frames=episode_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer(env, env_params, state_seq, cum_rewards)\n",
    "vis.animate(osp.join(\"results\",f\"{gym_env}-ppo.gif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run training with ES or PPO. Store logs and agent ckpt.\"\"\"\n",
    "ppo_yaml = osp.join(\"expert_agents\",\"CartPole-v1\",\"ppo.yaml\")\n",
    "seed_id = 123\n",
    "lrate = 5e-04\n",
    "\n",
    "config = load_config(ppo_yaml, seed_id, lrate)\n",
    "\n",
    "rng = jax.random.PRNGKey(config.train_config.seed_id)\n",
    "# Setup the model architecture\n",
    "rng, rng_init = jax.random.split(rng)\n",
    "model, policy_params = get_model_ready(rng_init, config.train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T23:08:41.810124Z",
     "start_time": "2025-01-07T23:08:41.695052Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_step(action, state):\n",
    "    return jax.vmap(cartpole_step, in_axes=(0,0))(\n",
    "        action, state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T23:09:19.605351Z",
     "start_time": "2025-01-07T23:09:19.450369Z"
    }
   },
   "outputs": [],
   "source": [
    "state = jnp.array([0.1,0.1,0.1,0.1])\n",
    "action = jnp.array([-1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = cartpole_step(action,state)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_batch = [jnp.array(np.random.randn(5,)),\n",
    "                       jnp.array(np.random.randn(5,)),\n",
    "                       jnp.array(np.random.randn(5,)),\n",
    "                       jnp.array(np.random.randn(5,))]\n",
    "state_batch = jnp.stack(state_batch,axis=1)\n",
    "action_batch = jnp.array(np.random.randint(0,2,5)).astype(float).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state  = batch_step(\n",
    "   action_batch,state_batch\n",
    ")\n",
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_batch = [jnp.ones(5),\n",
    "                       jnp.ones(5),\n",
    "                       jnp.ones(5),\n",
    "                       jnp.ones(5)]\n",
    "state_batch = jnp.stack(state_batch,axis=1)\n",
    "action_batch = jnp.ones(5).reshape(-1,1)*-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state  = batch_step(\n",
    "   action_batch,state_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jit-Compiled Episode Rollout\n",
    "from functools import partial\n",
    "\n",
    "jit_rollout = jax.jit(partial(kinematics,step_fn=cartpole_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = jnp.ones(4)*0.1\n",
    "action = jnp.array(np.random.randint(0,2,10)).reshape(-1,1)\n",
    "action.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rollout = jit_rollout(action,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_t =  jnp.array([0.25,.1,0.2,0.3])\n",
    "action = jnp.array([15])\n",
    "for t in range(10):\n",
    "  state_t = cartpole_step(action,state_t)\n",
    "  print(state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = jnp.array([0.25,.1,0.2,0.3])\n",
    "action = jnp.ones(10).reshape(-1,1)*15\n",
    "x_rollout = jit_rollout(action,state)\n",
    "x_rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cartpole_dynamics = jax.vmap(jit_rollout,in_axes=(0,None))\n",
    "\n",
    "action = jnp.ones((10,5,1))*15\n",
    "\n",
    "cartpole_dynamics(action,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
